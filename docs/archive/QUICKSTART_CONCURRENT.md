# ğŸš€ å¿«é€Ÿå¼€å§‹ï¼šRSSå¹¶å‘æŠ“å–

## 1ï¸âƒ£ å®‰è£…ä¾èµ– (1åˆ†é’Ÿ)

```bash
pip install aiohttp>=3.8.0
```

## 2ï¸âƒ£ ä½¿ç”¨å¹¶å‘æ¨¡å¼ (ä¿®æ”¹1è¡Œä»£ç )

### ä¿®æ”¹ `src/main.py`:

**åŸä»£ç **:
```python
from search import SearchPipeline
```

**æ–°ä»£ç **:
```python
from search.search_pipeline_v2 import SearchPipelineV2 as SearchPipeline
```

å°±è¿™ä¹ˆç®€å•ï¼å…¶ä»–ä»£ç å®Œå…¨ä¸ç”¨åŠ¨ã€‚

## 3ï¸âƒ£ è¿è¡Œæµ‹è¯• (å¯é€‰)

```bash
# æ€§èƒ½åŸºå‡†æµ‹è¯•
cd tests
python benchmark_rss_performance.py

# æŸ¥çœ‹ç¤ºä¾‹
cd examples
python concurrent_rss_examples.py
```

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

- âš¡ **æ€§èƒ½æå‡**: 81.8%
- â±ï¸ **è€—æ—¶**: ä» 86ç§’ é™è‡³ 15ç§’
- ğŸš€ **åŠ é€Ÿæ¯”**: 5.5å€
- ğŸ’¾ **å†…å­˜å¢åŠ **: çº¦12MB

## ğŸ›ï¸ é«˜çº§é…ç½®ï¼ˆå¯é€‰ï¼‰

```python
from search.search_pipeline_v2 import SearchPipelineV2

pipeline = SearchPipelineV2(
    hours=24,
    use_concurrent=True,  # å¯ç”¨å¹¶å‘
    max_concurrent=10     # å¹¶å‘æ•°ï¼ˆæ ¹æ®æœåŠ¡å™¨è°ƒæ•´ï¼‰
)
```

## ğŸ”„ å›é€€æ–¹æ¡ˆ

å¦‚æœ‰é—®é¢˜ï¼Œç«‹å³å›é€€ï¼š

```python
# æ–¹æ³•1: å…³é—­å¹¶å‘
pipeline = SearchPipelineV2(use_concurrent=False)

# æ–¹æ³•2: ä½¿ç”¨åŸç‰ˆ
from search import SearchPipeline  # æ¢å¤åŸå¯¼å…¥
```

## ğŸ“š è¯¦ç»†æ–‡æ¡£

- å®Œæ•´æŒ‡å—: [CONCURRENT_RSS_MIGRATION.md](./CONCURRENT_RSS_MIGRATION.md)
- åŠŸèƒ½è¯´æ˜: [RSS_CONCURRENT_README.md](./RSS_CONCURRENT_README.md)
- ä¼˜åŒ–æ€»ç»“: [OPTIMIZATION_SUMMARY.md](./OPTIMIZATION_SUMMARY.md)

---

**å°±è¿™ä¹ˆç®€å•ï¼ä¸€è¡Œä»£ç ï¼Œæ€§èƒ½æå‡80%+ ğŸ‰**
