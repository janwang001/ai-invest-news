#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GitHubçˆ†æ¬¾é¡¹ç›®ç›‘æ§

ç›‘æ§AIç›¸å…³çš„çˆ†æ¬¾å¼€æºé¡¹ç›®:
- Starå¢é€Ÿ >1000/å¤©
- æ¥è‡ªé¡¶çº§ç»„ç»‡ (OpenAI, Meta, Google, Microsoftç­‰)
- Fork/Staræ¯” >0.3ï¼ˆé«˜å®ç”¨æ€§ï¼‰

çˆ†æ¬¾é¡¹ç›® = æŠ€æœ¯è¶‹åŠ¿ä¿¡å·
"""

import logging
import time
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import requests

logger = logging.getLogger(__name__)


class GitHubMonitor:
    """GitHubçˆ†æ¬¾é¡¹ç›®ç›‘æ§å™¨"""

    def __init__(self):
        # GitHub APIåŸºç¡€URL
        self.api_base = "https://api.github.com"

        # é‡ç‚¹å…³æ³¨çš„ç»„ç»‡
        self.priority_orgs = [
            "openai", "anthropics", "google", "meta", "microsoft",
            "huggingface", "langchain-ai", "deepmind", "stability-ai",
            "mistralai", "ollama", "ggerganov",
        ]

        # AIç›¸å…³å…³é”®è¯
        self.ai_keywords = [
            "llm", "gpt", "transformer", "diffusion", "ai", "ml",
            "neural", "deep-learning", "machine-learning",
            "chatbot", "agent", "rag", "embedding", "vector",
            "llama", "mistral", "claude", "gemini",
        ]

        # çˆ†æ¬¾é˜ˆå€¼
        self.thresholds = {
            "stars_per_day": 500,      # æ—¥å¢Staræ•°
            "min_stars": 1000,          # æœ€å°Staræ•°
            "min_fork_ratio": 0.2,      # Fork/Staræ¯”
            "trending_days": 7,         # è¶‹åŠ¿è®¡ç®—å¤©æ•°
        }

        self.headers = {
            "Accept": "application/vnd.github.v3+json",
            "User-Agent": "AI-Investment-Monitor/1.0",
        }

        # å¦‚æœæœ‰GitHub Tokenï¼Œæ·»åŠ åˆ°headers
        # self.headers["Authorization"] = f"token {os.environ.get('GITHUB_TOKEN', '')}"

    def search_trending_repos(self, days: int = 7, min_stars: int = 1000) -> List[Dict]:
        """
        æœç´¢è¶‹åŠ¿é¡¹ç›®

        Args:
            days: æ—¶é—´èŒƒå›´
            min_stars: æœ€å°Staræ•°

        Returns:
            é¡¹ç›®åˆ—è¡¨
        """
        try:
            # è®¡ç®—æ—¥æœŸèŒƒå›´
            since_date = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")

            # æ„å»ºæœç´¢æŸ¥è¯¢
            # æœç´¢AIç›¸å…³çš„é«˜Staré¡¹ç›®
            queries = [
                f"stars:>{min_stars} created:>{since_date} language:python topic:llm",
                f"stars:>{min_stars} created:>{since_date} topic:machine-learning",
                f"stars:>{min_stars} pushed:>{since_date} topic:artificial-intelligence",
            ]

            all_repos = []
            seen_ids = set()

            for query in queries:
                try:
                    url = f"{self.api_base}/search/repositories"
                    params = {
                        "q": query,
                        "sort": "stars",
                        "order": "desc",
                        "per_page": 30,
                    }

                    response = requests.get(
                        url,
                        headers=self.headers,
                        params=params,
                        timeout=15
                    )

                    if response.status_code == 403:
                        logger.warning("GitHub APIé€Ÿç‡é™åˆ¶")
                        break

                    response.raise_for_status()
                    data = response.json()

                    for repo in data.get("items", []):
                        if repo["id"] not in seen_ids:
                            seen_ids.add(repo["id"])
                            processed = self._process_repo(repo)
                            if processed:
                                all_repos.append(processed)

                    time.sleep(2)  # APIé€Ÿç‡é™åˆ¶

                except Exception as e:
                    logger.warning(f"æœç´¢æŸ¥è¯¢å¤±è´¥: {e}")
                    continue

            # æŒ‰ä¼˜å…ˆçº§æ’åº
            all_repos.sort(
                key=lambda x: (
                    0 if x["priority"] == "P0" else 1 if x["priority"] == "P1" else 2,
                    -x["stars"]
                )
            )

            logger.info(f"GitHub: å‘ç° {len(all_repos)} ä¸ªè¶‹åŠ¿é¡¹ç›®")
            return all_repos[:20]  # æœ€å¤šè¿”å›20ä¸ª

        except Exception as e:
            logger.error(f"æœç´¢GitHubé¡¹ç›®å¤±è´¥: {e}")
            return []

    def check_org_repos(self, org: str, days: int = 7) -> List[Dict]:
        """
        æ£€æŸ¥ç‰¹å®šç»„ç»‡çš„æ–°é¡¹ç›®

        Args:
            org: ç»„ç»‡å
            days: æ—¶é—´èŒƒå›´

        Returns:
            é¡¹ç›®åˆ—è¡¨
        """
        try:
            url = f"{self.api_base}/orgs/{org}/repos"
            params = {
                "sort": "created",
                "direction": "desc",
                "per_page": 10,
            }

            response = requests.get(
                url,
                headers=self.headers,
                params=params,
                timeout=15
            )

            if response.status_code == 404:
                logger.debug(f"ç»„ç»‡ä¸å­˜åœ¨: {org}")
                return []

            response.raise_for_status()
            repos = response.json()

            since_date = datetime.now() - timedelta(days=days)
            results = []

            for repo in repos:
                created_at = datetime.strptime(
                    repo["created_at"], "%Y-%m-%dT%H:%M:%SZ"
                )

                if created_at > since_date:
                    processed = self._process_repo(repo, from_priority_org=True)
                    if processed:
                        results.append(processed)

            return results

        except Exception as e:
            logger.error(f"æ£€æŸ¥ç»„ç»‡ {org} å¤±è´¥: {e}")
            return []

    def fetch_all_trending(self, days: int = 7) -> List[Dict]:
        """
        è·å–æ‰€æœ‰è¶‹åŠ¿é¡¹ç›®

        Args:
            days: æ—¶é—´èŒƒå›´

        Returns:
            é¡¹ç›®åˆ—è¡¨
        """
        all_repos = []

        # 1. æœç´¢è¶‹åŠ¿é¡¹ç›®
        trending = self.search_trending_repos(days)
        all_repos.extend(trending)

        # 2. æ£€æŸ¥é‡ç‚¹ç»„ç»‡çš„æ–°é¡¹ç›®
        for org in self.priority_orgs[:5]:  # åªæ£€æŸ¥å‰5ä¸ªï¼Œé¿å…é€Ÿç‡é™åˆ¶
            try:
                org_repos = self.check_org_repos(org, days)
                all_repos.extend(org_repos)
                time.sleep(1)
            except Exception as e:
                logger.warning(f"æ£€æŸ¥ç»„ç»‡ {org} å¤±è´¥: {e}")

        # å»é‡
        seen = set()
        unique_repos = []
        for repo in all_repos:
            if repo["full_name"] not in seen:
                seen.add(repo["full_name"])
                unique_repos.append(repo)

        # æ’åº
        unique_repos.sort(
            key=lambda x: (
                0 if x["priority"] == "P0" else 1 if x["priority"] == "P1" else 2,
                -x["stars"]
            )
        )

        logger.info(f"GitHub: æ€»è®¡ {len(unique_repos)} ä¸ªè¶‹åŠ¿é¡¹ç›®")
        return unique_repos[:20]

    def _process_repo(self, repo: Dict, from_priority_org: bool = False) -> Optional[Dict]:
        """å¤„ç†ä»“åº“æ•°æ®"""
        try:
            name = repo.get("name", "")
            full_name = repo.get("full_name", "")
            description = repo.get("description", "") or ""
            stars = repo.get("stargazers_count", 0)
            forks = repo.get("forks_count", 0)
            owner = repo.get("owner", {}).get("login", "").lower()

            # æ£€æŸ¥æ˜¯å¦AIç›¸å…³
            is_ai_related = self._is_ai_related(name, description, repo.get("topics", []))

            if not is_ai_related and not from_priority_org:
                return None

            # è®¡ç®—ä¼˜å…ˆçº§
            priority = self._calculate_priority(
                stars, forks, owner, from_priority_org
            )

            # è®¡ç®—Forkæ¯”ç‡
            fork_ratio = forks / stars if stars > 0 else 0

            return {
                "name": name,
                "full_name": full_name,
                "description": description[:200],
                "url": repo.get("html_url", ""),
                "stars": stars,
                "forks": forks,
                "fork_ratio": round(fork_ratio, 2),
                "owner": owner,
                "language": repo.get("language", "Unknown"),
                "topics": repo.get("topics", [])[:5],
                "created_at": repo.get("created_at", ""),
                "updated_at": repo.get("updated_at", ""),
                "source": "GitHub",
                "priority": priority,
                "is_priority_org": owner in self.priority_orgs,
            }

        except Exception as e:
            logger.debug(f"å¤„ç†ä»“åº“å¤±è´¥: {e}")
            return None

    def _is_ai_related(self, name: str, description: str, topics: List[str]) -> bool:
        """åˆ¤æ–­æ˜¯å¦AIç›¸å…³"""
        text = f"{name} {description} {' '.join(topics)}".lower()

        for keyword in self.ai_keywords:
            if keyword in text:
                return True

        return False

    def _calculate_priority(
        self, stars: int, forks: int, owner: str, from_priority_org: bool
    ) -> str:
        """è®¡ç®—é¡¹ç›®ä¼˜å…ˆçº§"""
        # P0: æ¥è‡ªé¡¶çº§ç»„ç»‡ ä¸” é«˜Star
        if from_priority_org or owner in self.priority_orgs:
            if stars >= 5000:
                return "P0"
            elif stars >= 1000:
                return "P1"

        # P0: è¶…é«˜Starï¼ˆçˆ†æ¬¾ï¼‰
        if stars >= 10000:
            return "P0"

        # P1: é«˜Star
        if stars >= 3000:
            return "P1"

        # P2: ä¸€èˆ¬
        return "P2"

    def generate_test_data(self) -> List[Dict]:
        """ç”Ÿæˆæµ‹è¯•æ•°æ®"""
        return [
            {
                "name": "gpt-5-preview",
                "full_name": "openai/gpt-5-preview",
                "description": "Official GPT-5 API examples and documentation",
                "url": "https://github.com/openai/gpt-5-preview",
                "stars": 45000,
                "forks": 8500,
                "fork_ratio": 0.19,
                "owner": "openai",
                "language": "Python",
                "topics": ["gpt-5", "llm", "openai", "ai"],
                "created_at": datetime.now().strftime("%Y-%m-%dT%H:%M:%SZ"),
                "updated_at": datetime.now().strftime("%Y-%m-%dT%H:%M:%SZ"),
                "source": "GitHub",
                "priority": "P0",
                "is_priority_org": True,
            },
            {
                "name": "llama-4",
                "full_name": "meta-llama/llama-4",
                "description": "LLaMA 4: Open foundation language models",
                "url": "https://github.com/meta-llama/llama-4",
                "stars": 32000,
                "forks": 5200,
                "fork_ratio": 0.16,
                "owner": "meta-llama",
                "language": "Python",
                "topics": ["llama", "llm", "meta", "ai"],
                "created_at": datetime.now().strftime("%Y-%m-%dT%H:%M:%SZ"),
                "updated_at": datetime.now().strftime("%Y-%m-%dT%H:%M:%SZ"),
                "source": "GitHub",
                "priority": "P0",
                "is_priority_org": True,
            },
            {
                "name": "ai-agent-framework",
                "full_name": "langchain-ai/ai-agent-framework",
                "description": "Production-ready AI agent framework with RAG support",
                "url": "https://github.com/langchain-ai/ai-agent-framework",
                "stars": 8500,
                "forks": 1200,
                "fork_ratio": 0.14,
                "owner": "langchain-ai",
                "language": "Python",
                "topics": ["agent", "rag", "llm", "langchain"],
                "created_at": datetime.now().strftime("%Y-%m-%dT%H:%M:%SZ"),
                "updated_at": datetime.now().strftime("%Y-%m-%dT%H:%M:%SZ"),
                "source": "GitHub",
                "priority": "P1",
                "is_priority_org": True,
            },
        ]


def test_github_monitor():
    """æµ‹è¯•GitHubç›‘æ§å™¨"""
    print("=" * 60)
    print("GitHubçˆ†æ¬¾é¡¹ç›®ç›‘æ§å™¨æµ‹è¯•")
    print("=" * 60)

    monitor = GitHubMonitor()

    # æµ‹è¯•æ•°æ®
    print("\næµ‹è¯•1: æµ‹è¯•æ•°æ®ç”Ÿæˆ")
    test_repos = monitor.generate_test_data()
    print(f"  ç”Ÿæˆ {len(test_repos)} ä¸ªæµ‹è¯•é¡¹ç›®")

    for repo in test_repos:
        print(f"\n  [{repo['priority']}] {repo['full_name']}")
        print(f"    â­ {repo['stars']:,} | ğŸ´ {repo['forks']:,}")
        print(f"    {repo['description'][:60]}...")

    # æµ‹è¯•AIç›¸å…³åˆ¤æ–­
    print("\næµ‹è¯•2: AIç›¸å…³æ€§åˆ¤æ–­")
    test_cases = [
        ("llm-chatbot", "A chatbot using LLM", ["chatbot", "ai"], True),
        ("my-website", "Personal portfolio", ["web"], False),
        ("gpt-wrapper", "GPT API wrapper", [], True),
    ]

    for name, desc, topics, expected in test_cases:
        result = monitor._is_ai_related(name, desc, topics)
        status = "âœ…" if result == expected else "âŒ"
        print(f"  {status} {name} â†’ {result} (æœŸæœ›: {expected})")

    # æµ‹è¯•çœŸå®APIï¼ˆå¯èƒ½å¤±è´¥ï¼‰
    print("\næµ‹è¯•3: çœŸå®APIè·å–ï¼ˆå¯èƒ½å—é™ï¼‰")
    try:
        repos = monitor.search_trending_repos(days=7, min_stars=5000)
        print(f"  è·å–åˆ° {len(repos)} ä¸ªè¶‹åŠ¿é¡¹ç›®")

        for repo in repos[:3]:
            print(f"\n    [{repo['priority']}] {repo['full_name']}")
            print(f"      â­ {repo['stars']:,}")

    except Exception as e:
        print(f"  APIè·å–å¤±è´¥: {e}")

    print("\næµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    test_github_monitor()
